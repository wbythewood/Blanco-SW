{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data for noise\n",
    "This part of the code will be used to download noise data.\n",
    "\n",
    "It is based on Josh Russell's **fetch_NOISE**.\n",
    "\n",
    "*william b hawley april 2020*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "from obspy.geodetics import gps2dist_azimuth, locations2degrees\n",
    "from obspy.io.sac import SACTrace\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if data directory exists\n",
    "if not os.path.exists(NoiseDataDir):\n",
    "    os.makedirs(NoiseDataDir)\n",
    "\n",
    "# load the client\n",
    "client = Client(webservice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stations\n",
    "\n",
    "t1 = UTCDateTime(tstart)\n",
    "t1 = t1 - (60*60*24)*noDays\n",
    "t2 = UTCDateTime(tend)\n",
    "\n",
    "inventory = client.get_stations(network=network, station=','.join(StaList), channel=','.join(ChanList), starttime=t1, endtime=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with days to download\n",
    "\n",
    "# load event file\n",
    "ifn = open(EventsFileName)\n",
    "DayList = []\n",
    "with open(DayFileName,'w') as f:\n",
    "    for line in ifn:\n",
    "        evDate = UTCDateTime(line)\n",
    "        if isCalDay == 1:\n",
    "            evDate = UTCDateTime(evDate.year,evDate.month,evDate.day)\n",
    "        for iday in range(1,noDays+1):\n",
    "            date = evDate-(60*60*24)*iday\n",
    "            date = datetime.strptime(str(date),'%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            date = date.strftime('%Y%m%d%H%M')\n",
    "            f.write(date+'\\n')\n",
    "            DayList.append(date)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on station BB030...\n",
      "Working on station BB060...\n",
      "Working on station BB070...\n",
      "Working on station BB090...\n",
      "Working on station BB120...\n",
      "Working on station BB130...\n",
      "Working on station BB140...\n",
      "Working on station BB150...\n",
      "Working on station BB170...\n",
      "Working on station BB180...\n",
      "Working on station BB200...\n",
      "Working on station BB230...\n",
      "Working on station BB240...\n",
      "Working on station BB260...\n",
      "Working on station BB290...\n",
      "Working on station BB300...\n",
      "Working on station BB320...\n",
      "Working on station BB330...\n",
      "Working on station BB350...\n",
      "Working on station BB370...\n",
      "Working on station BB390...\n",
      "Working on station BB410...\n",
      "Working on station BB420...\n",
      "Working on station BB440...\n",
      "Working on station BB450...\n",
      "Working on station BB480...\n",
      "Working on station BB510...\n",
      "Working on station BB530...\n",
      "Working on station BB540...\n",
      "Working on station BB550...\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "\n",
    "# get stations with BXH channel\n",
    "XStationList = open(XStafn)\n",
    "\n",
    "# loop through stations\n",
    "for ista in range(0,len(inventory[0])):\n",
    "    \n",
    "    # get station info\n",
    "    stel = inventory[0].stations[ista].elevation\n",
    "    stla = inventory[0].stations[ista].latitude\n",
    "    stlo = inventory[0].stations[ista].longitude\n",
    "    stnm = inventory[0].stations[ista].code\n",
    "    # make station file\n",
    "    print(\"Working on station \"+stnm+\"...\")\n",
    "    staDir = NoiseDataDir + network + '_' + stnm + '/'\n",
    "    if not os.path.exists(staDir):\n",
    "        os.makedirs(staDir)\n",
    "    \n",
    "    # loop through days in noise day file\n",
    "    for iday in DayList:\n",
    "        time1 = UTCDateTime(iday)\n",
    "        year = str(time1.year)\n",
    "        jday = str(\"{:03d}\".format(time1.julday))\n",
    "        hh = str(\"{:02d}\".format(time1.hour))\n",
    "        mm = str(\"{:02d}\".format(time1.minute))\n",
    "        ss = str(\"{:02d}\".format(time1.second))\n",
    "        time2 = time1 + (60*60*24)\n",
    "        \n",
    "        # loop through channels\n",
    "        for comp in ChanList:\n",
    "            # if a BXH exists, use that.\n",
    "            if comp == 'BDH':\n",
    "                if stnm in XStationList:\n",
    "                    comp = 'BXH'\n",
    "                    print(\"Using comp \"+comp+\" for station \"+stnm)\n",
    "            # download\n",
    "            try:\n",
    "                st = client.get_waveforms(network=network, station=stnm, location='*', channel=comp, starttime=time1, endtime=time2, attach_response=True)\n",
    "            except Exception:\n",
    "                print('Missing data for station: ',station)\n",
    "                continue\n",
    "            \n",
    "            # if BXH, change back ... doesn't matter; we downsample to 1 Hz anyway\n",
    "            if comp == 'BXH':\n",
    "                comp = 'BDH'\n",
    "\n",
    "            sr = st[0].stats.sampling_rate\n",
    "            \n",
    "            # check for gaps\n",
    "            if len(st) > 1:\n",
    "                st.merge(method=1, fill_value=0)\n",
    "            \n",
    "            # remove response\n",
    "            if isRemoveResp:\n",
    "                try:\n",
    "                    st.remove_response(output=\"DISP\", zero_mean=True, taper=True, taper_fraction=0.05, pre_filt=[0.001, 0.005, sr/3, sr/2], water_level=60)\n",
    "                except Exception:\n",
    "                    print('Failed to remove response: ' + iday)\n",
    "                    continue\n",
    "\n",
    "            st.trim(starttime=time1, endtime=time2, pad=True, nearest_sample=False, fill_value=0) # make sure correct length\n",
    "            st.detrend(type='demean')\n",
    "            st.detrend(type='linear')\n",
    "            st.taper(type=\"cosine\",max_percentage=0.05)\n",
    "            \n",
    "            # downsample\n",
    "            if isDownsamp and sr!=srNew:\n",
    "                st.filter('lowpass', freq=0.4*srNew, zerophase=True) # anti-alias filter\n",
    "                st.decimate(factor=int(sr/srNew), no_filter=True) # downsample\n",
    "                st.detrend(type='demean')\n",
    "                st.detrend(type='linear')\n",
    "                st.taper(type=\"cosine\",max_percentage=0.05)\n",
    "\n",
    "            # convert to SAC and fill out station/event header info\n",
    "            sac = SACTrace.from_obspy_trace(st[0])\n",
    "            sac.stel = stel\n",
    "            sac.stla = stla\n",
    "            sac.stlo = stlo\n",
    "            sac.kcmpnm = comp\n",
    "            sac.delta = (1/srNew)\n",
    "            \n",
    "            # write sac file\n",
    "            sac_out = staDir + stnm + '.' + year + '.' + jday + '.' + hh + '.' + mm + '.' + ss + '.' + comp + '.sac'\n",
    "            sac.write(sac_out)\n",
    "XStationList.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DayList = [DayList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-11-15T18:12:00.000000Z\n",
      "2012-11-15T00:00:00.000000Z\n"
     ]
    }
   ],
   "source": [
    "timetest = UTCDateTime(DayList[0])\n",
    "print(timetest)\n",
    "timetest2 = UTCDateTime(timetest.year,timetest.month,timetest.day)\n",
    "print(timetest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/whawley/Research/github/Blanco-SW/dataNoise/X9_BB030/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
